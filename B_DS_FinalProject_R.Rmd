---
title: 'APPENDIX - R-script'
author: "S102778"
date: "9/12/2021"
output:
  pdf_document: default
  html_document: default
---

**RELEVANT R PACKAGES TO RUN THE FULL SCRIPT**

```{r, message = FALSE}
library(tidyverse)
library(dplyr)
library(tidymodels)
library(readr)
library(ggplot2)
library(gapminder)
library(rsample)
library(margins)
library(caret)
library(stargazer)
library(lattice)
library(tidytext)
library(quanteda)
library(pacman)
tinytex::install_tinytex()
```

# Data work: Task one


**LOADING THE DATA**

```{r}

load("~/Desktop/Introduction to Data Science for Business and Social Applications/Final Exam/exam-2021.RData")

```



**UID, WRANGLING AND JOINGING**

I start of by finding out what is uniquely identifying, and creating a UID based on that (cik and year)
```{r}
companies <- mutate(companies, uid = paste(cik, year, sep = "-")) 
reports <- mutate(reports, uid = paste(cik, year, sep = "-"))
```

Then i compute a left_join to create a full data set of the two and selects the relevant variables only
```{r}
names <- left_join(companies, reports, by = "uid")

name <- names %>%
  select(cik.x, year.x, at, capx,ceq, ch, cogs, dltt, dpact, ni, ppegt, sale,
         wcap, uid, text, name_change)

name <- name %>% 
  rename(cik=cik.x, year=year.x)

head(name)

```



**SUMMARIZING**

```{r}
dim(name)

summary(name)
```

**Table 1**: Created manually in Excel with information from the following command: 
```{r}
str(name)
```




# Data work: Task two

**WORKING WITH TEXT AS DATA**

New DF: Unnesting tokens in the text variable and removing stop words
```{r, message=FALSE}
name_text <- name %>% 
  unnest_tokens(word, text) %>%
  anti_join(stop_words)
```

```{r}
name_text %>%
  slice_head(n = 12)
```

**Table 2:** Most frequent words, no sentiment 
```{r}
name_text %>%
  count(word, sort = TRUE) %>%
  slice_head(n=30)
```

Adding sentiment - keeps only words with sentiment attached from Bing sentiment dictionary
```{r, message=FALSE}
name_text_senti <- name_text %>% 
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE)
```

```{r}
head(name_text_senti)
```

**Figure 1:** Words that contribute to positive and negative sentiment / Bing  
```{r}
name_text_senti %>%
  group_by(sentiment) %>%
  slice_max(n, n = 15) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>% 
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~sentiment, scales = "free_y") + 
  theme_minimal() +
  scale_fill_manual(values = c("#D16103", "#F4EDCA")) +
  labs(x = "Frequency of words", y = NULL,
       title = "Words that contribute to positive and negative sentiment within the 8-K filings",
       subtitle = "Based entirely on words available within the Bing sentiment dictionary")
```





# Modelling: Task one (Logit)


**LOGISTIC REGRESSION**

Creating a dataset with the relevant variables / converting the outcome variable to a factor format
```{r}
logit <- name %>%
  select(at, capx, ceq, ch, cogs, dltt, dpact, ni, ppegt, sale, wcap, name_change)

logit$name_change <- as.factor(logit$name_change)
```


From here i am ready to start my modelling:
```{r, warning=FALSE}
set.seed(200)

logit_split <- logit %>% rsample::initial_split(prop = 0.8)
logit_train <- training(logit_split )
logit_test <- testing(logit_split )

m1_logit <- glm(name_change ~ ., data = logit_train, family = binomial (link = "logit"))

coef_m1_logit <- coef(m1_logit)
```

Summary of Model 1: 
```{r}
summary(m1_logit)
```

**Table 3:** Model coefficients for Model 1 - The logistic regression (log odds ratio)
```{r}
stargazer(coef_m1_logit, type = "text", title = "Table 3: Model Coefficients for Model 1 
          - Logistic regression (log odds ratio)", out = "coef_m1_logit.html")
```

Getting confidence intervals for Model 1 (log odds ratio)
```{r, warning=FALSE}
confint_m1_logit <- confint(m1_logit)
```


**Table 4:** Confidence intervals for Model 1 - Logistic regression (log odds ratio)
```{r}
stargazer(confint_m1_logit, type = "text", title = "Table 4: Confidence intervals for Model 1 -
          Logistic Regression (log odds ratio)", out = "confint.html")
```

Calculating the Average Marginal Effect for each predictor for the correct interpretation: 
```{r}
ame_m1_logit <- margins(m1_logit) 

est_ame_m1_logit <- as.data.frame(summary(ame_m1_logit)) 

est_ame_m1_logit
```

**Table 5:** The Average Marginal Effect for each predictor in a nice format
```{r}
stargazer(est_ame_m1_logit, type = "text", title = "Table 5: The Average Marginal Effect for
          each predictor variable",summary = FALSE, out = "m1_logit_ame.html")
```


**IN-SAMPLE PREDICTED PROBABILITIES (Logit)**

```{r}
logit_train$pred_prob <- predict(m1_logit, type = "response")

logit_train$pred_class_correct <- ifelse(logit_train$pred_prob > median(logit_train$pred_prob), 1, 0)

confm_in <- confusionMatrix(factor(logit_train$name_change),
                           factor(logit_train$pred_class_correct))
```

**Table 6:** Confusion Matrix (in-sample)
```{r}
confm_in


recall(factor(logit_train$name_change),
       factor(logit_train$pred_class_correct))

precision(factor(logit_train$name_change),
          factor(logit_train$pred_class_correct))
```



**OUT-OF-SAMPLE PREDICTED PROBABILITIES (Logit)**

```{r}
logit_test$pred_prob <- predict(m1_logit, newdata = logit_test, type = "response")

logit_test$pred_class_correct <- ifelse(logit_test$pred_prob > median(logit_test$pred_prob), 1, 0)

confm_out <- confusionMatrix(factor(logit_test$name_change),
                             factor(logit_test$pred_class_correct))
```

Table 7: Confusion Matrix (out-of-sample) + recall and precision
```{r}
confm_out

recall(factor(logit_test$name_change),
       factor(logit_test$pred_class_correct))

precision(factor(logit_test$name_change),
          factor(logit_test$pred_class_correct))
```



# Modelling: Task two (Lasso)

**REGUARLIZED MODEL: LASSO REGRESSION**

```{r}
pacman::p_load(tidyverse, quanteda, ggplot2, glmnet, caret, pROC, dplyr)
```

**PREPARING THE DATA**

Making a separate dataset with only uid, text and name_change
```{r}
filing <- name %>%
  select(uid, text, name_change)
```

How many changed name vs. not
```{r}
table(filing$name_change, useNA = "always")
```

Imbalance ratio (for evaluating accuracy)
```{r}
imbalanceRatio <- 127/231
imbalanceRatio
```

Creating a quanteda corpus 
```{r, warning=FALSE}
filing_corp <- corpus(filing$text, 
                      docvars = data.frame(name_change = filing$name_change, 
                                           uid       = filing$uid))

filing_dfm <- filing_corp %>%
  tokens() %>%
  dfm(remove = stopwords("en")) 


docvars(filing_dfm) <- data.frame(name_change = filing$name_change,
                                  uid       = filing$uid)
```

Trimming away very infrequent tokens 
```{r}
filing_dfm <- dfm_trim(filing_dfm, min_docfreq = 2)
dim(filing_dfm)


filing_dfm[1:6, 1:6]
```

For reproducability 
```{r}
set.seed(200)
```

I already have a uid for all observations - making an 80/20 split
```{r}
uid <- filing$uid

training <- sample(1:length(uid), 
                   floor(.80*length(uid)))

test <- (1:length(uid))[1:length(uid) %in% training == FALSE]

train_id <- uid[training]
test_id <- uid[test]

train_dfm <- dfm_subset(filing_dfm, uid %in% train_id)
test_dfm <- dfm_subset(filing_dfm, uid %in% test_id)
```


**BUILDING THE LASSO REGRESSION**

For reproducability
```{r}
set.seed(200)
```

Cross-validation
```{r, warning=FALSE}
lasso <- cv.glmnet(x = train_dfm, y = docvars(train_dfm, "name_change"),
                   family = "binomial", alpha = 1, nfolds = 5, # for lasso we set alpha to be 1 
                   parallel = TRUE, intercept = TRUE,
                   type.measure = "class")
```

Fitting the model
```{r}
lasso_fit <- glmnet(x=train_dfm, y = docvars(train_dfm, "name_change"), 
                    alpha = 1, lambda = lasso$lambda.min, 
                    standardize = TRUE,
                    family = "binomial")

lasso$lambda.min
```

**Figure 2:** Lasso Cross-Validation (Misclassification errors against log(Lambda)) 
```{r}
plot(lasso)
```


**EXTRACTING TOP PREDICTIVE FEATURES FROM THE LASSO**

```{r}
best.lambda <- which(lasso$lambda == lasso$lambda.min)

best.lambda

beta <- lasso$glmnet.fit$beta[,best.lambda] 
```

Finding the number of non-zero beta's
```{r}
sum(beta != 0)
```

Finding most important words: 
```{r}
word_lasso <- data.frame(lasso_est = as.numeric(beta),
                         lasso_choice = names(beta),
                         stingsAsFactors = FALSE) %>%
  arrange(desc(lasso_est)) %>%
  head(15)

head(word_lasso, n = 15)
```

**Table 8:** The top 15 most important words according to Model 2 - Lasso Regression
```{r}
stargazer(word_lasso, type = "text", title = "Table 8: The Top 15 most important words according
          to Model 2 - Lasso Regression", summary = FALSE, out = "word_lasso.html")
```



**ROC AND AUC FOR LASSO (in-sample)**
```{r}
train_lasso <- predict(lasso, newx = train_dfm, 
                       type = "response", s = lasso$lambda.min)

train_lasso <- data.frame(train_lasso,
                          docvars(train_dfm, "name_change"))

 
names(train_lasso) <- c("train_prob", "true_class")
```

The ROC curve for LASSO (in-sample)
```{r}
train_roc_lasso <- roc(train_lasso$true_class, train_lasso$train_prob)
```

**Figure 3:** Lasso in-sample ROC curve:
```{r}
plot(train_roc_lasso)
```

Thresholds, TPR and TNR
```{r}
dec_lasso <- data.frame(thres = train_roc_lasso$thresholds, # thresholds
                        tp = train_roc_lasso$sensitivities, # true positive,
                        tn = train_roc_lasso$specificities) # true negative

```

Calculating the absolute difference between TPR and TNR
```{r}
dec_lasso$dist <- abs(dec_lasso$tp - dec_lasso$tn)
```


Threshold associated with the minimum value
```{r}
dec_lasso %>% 
  filter(dist == min(dist)) %>%
  dplyr::select(thres)
```

In-sample AUC
```{r}
auc(train_lasso$true_class, train_lasso$train_prob)
```



**MOVING OUT OF SAMPLE - USING THE THRESHOLD FROM ABOVE IN THE LASSO PREDICTION**
Predicting on the Lasso
```{r}
pred_lasso<- predict(lasso, newx = test_dfm, 
                     type = "response", s = lasso$lambda.min)

pred_lasso <- data.frame(pred_lasso,
                         docvars(test_dfm, "name_change"))

names(pred_lasso) <- c("pred_prob", "true_class")
```

Getting the out-of-sample ROC  
```{r}
p_roc_lasso <- roc(pred_lasso$true_class, pred_lasso$pred_prob)
```

**Figure 4:** Lasso out-of-sample ROC curve
```{r}
plot(p_roc_lasso)
```

Out-of-sample AUC:
```{r}
auc(pred_lasso$true_class, pred_lasso$pred_prob)
```

Implementing the optimal threshold
```{r}
pred_lasso$pred_name_change <- ifelse(pred_lasso$pred_prob > 0.30, 1, 0)
```

**Table 9:** Confusion Matrix (out-of-sample) + recall and precision 
```{r}
confusionMatrix(factor(pred_lasso$true_class), 
                factor(pred_lasso$pred_name_change))

precision(factor(pred_lasso$true_class), 
          factor(pred_lasso$pred_name_change))

recall(factor(pred_lasso$true_class), 
       factor(pred_lasso$pred_name_change))
```

**Table 10:** Out-of-sample model performance comparison (Logit vs. Lasso)

*Table 10 was manually produced in Excel with the calculated values of the out-of-sample confusion matrix, recall and precision for both Logit and Lasso*





