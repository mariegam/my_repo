{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f389837f",
   "metadata": {},
   "source": [
    "# Question 3 - Text Document Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce692d0",
   "metadata": {},
   "source": [
    "## Program code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e94d0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6183036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Corpus class used to run the text document similarity program\n",
    "class Corpus:\n",
    "    \"\"\"\n",
    "    Class to compute to the document similarity between different documents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, lowercase=True, remove_punctuation=True, remove_numbers=True):\n",
    "        \"\"\"\n",
    "        Initiates a new Corpus object.\n",
    "        Also defines what string cleaning processes should be done on the Corpus documents and search document.\n",
    "        \n",
    "        Args:\n",
    "            name: Name of the new corpus, can be of any type (string, float etc.)\n",
    "            lowercase: Whether to transform the documents to lowercase (default: True) \n",
    "            remove_punctuation: Whether to remove punctuation from the documents (default: True)\n",
    "            remove_numbers: Whether to remove numbers from the documents (default: True)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.documents = []\n",
    "        self.word_dict = {}\n",
    "        self.array_all_vectors = None\n",
    "        self.lowercase = lowercase\n",
    "        self.remove_punctuation = remove_punctuation \n",
    "        self.remove_numbers = remove_numbers\n",
    "\n",
    "\n",
    "    def add_doc(self, document):\n",
    "        \"\"\"\n",
    "        Funtion to add new documents to the corpus.\n",
    "        When the document has been removed, the word vectors and word dictionary is recalculated for the corpus.\n",
    "        \n",
    "        Args:\n",
    "            document: Document to be added to the corpus, can be a list of documents or a single document. \n",
    "\n",
    "        Returns:\n",
    "            None  \n",
    "        \"\"\"\n",
    "        \n",
    "        # add a list of documents to the corpus\n",
    "        # checks if input is a list of strings\n",
    "        if ( isinstance(document, list) ) and ( all(isinstance(item, str) for item in document) ):\n",
    "            # add the list of documents to the corpus\n",
    "            self.documents.extend(document)\n",
    "            \n",
    "            # re-calculate word dictionary and word vectors for new Corpus\n",
    "            self.create_vector_representation()\n",
    "        \n",
    "        # add one single document to the corpus\n",
    "        # checks if input is a string\n",
    "        elif isinstance(document, str):\n",
    "            # add the document to the corpus\n",
    "            self.documents.append(document)\n",
    "            \n",
    "            # re-calculate word dictionary and word vectors for new Corpus\n",
    "            self.create_vector_representation()\n",
    "            \n",
    "        # print an error if input is neither string or list of strings\n",
    "        else:\n",
    "            print(f\"Error: Input document(s) must be a string or a list of strings. No new documents added to the {self.name} corpus, please try again.\")\n",
    "            \n",
    "        return\n",
    "\n",
    "            \n",
    "    def remove_doc(self, document):\n",
    "        \"\"\"\n",
    "        Funtion to remove a document from the corpus. \n",
    "        When the document has been removed, the word vectors and word dictionary is recalculated for the corpus.\n",
    "        \n",
    "        Args:\n",
    "            document: Document to be added to the corpus, can be a list of documents or a single document. \n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        \n",
    "        # remove documents from the corpus\n",
    "        try:\n",
    "            self.documents.remove(document)\n",
    "            \n",
    "            # re-calculate word dictionary and word vectors for new Corpus\n",
    "            self.create_vector_representation()\n",
    "        \n",
    "        # try/except is appropriate \n",
    "        except ValueError:\n",
    "            if type(document) == str:\n",
    "                print(f\"Error: Input document does not exist in the {self.name} corpus, please try again.\")\n",
    "            elif type(document) == list:\n",
    "                print(f\"Error: Only one document can be removed at a time, please try again.\")\n",
    "            else:\n",
    "                print(\"Error: Invalid input entered. The input must be a single document, please try again.\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def show_docs(self):\n",
    "        \"\"\" \n",
    "        Function to print out a list of all documents in the Corpus\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Return:\n",
    "            None\n",
    "            \n",
    "        Print to screen:\n",
    "            List of all documents in the Corpus\n",
    "        \"\"\"\n",
    "        \n",
    "        nl = '\\n -> '\n",
    "\n",
    "        print(f\"All documents in the {self.name} Corpus: {nl}{nl.join(self.documents)}\\n\")\n",
    "\n",
    "        return\n",
    "            \n",
    "    def create_vector_representation(self):\n",
    "        \"\"\"\n",
    "        Helper function to compute a dictionary of the corpus and \n",
    "        create a vector represention of the documents in the corpus. \n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            Vector representation of the documents in the corpus.\n",
    "        \"\"\"\n",
    "\n",
    "        # create dictionary of words with unique words as key and count as values\n",
    "        for document in self.documents:\n",
    "            \n",
    "            # make the text lowercase to not differenciate between upper and lowercase words\n",
    "            if self.lowercase == True:\n",
    "                document = document.lower()\n",
    "                        \n",
    "            if self.remove_punctuation == True:\n",
    "\n",
    "                # remove puntuation\n",
    "                punctuation_all = \"!#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "\n",
    "                # replace all punctuation with a empty space\n",
    "                for punctuation in punctuation_all:\n",
    "                    document = document.replace(punctuation, ' ')\n",
    "                \n",
    "            if self.remove_numbers == True:\n",
    "                \n",
    "                # remove numbers from the document\n",
    "                numbers = ['0123456789']\n",
    "                \n",
    "                for number in numbers:\n",
    "                    document = document.replace(number, ' ')\n",
    "            \n",
    "            # Split the document into single words and iterate over the words to check if it appears in the corpus\n",
    "            for word in document.split(): # split makes spaces to commas by default \n",
    "                \n",
    "                # Count how many times the word appears in the corpus and set it as a value of the dictioary.\n",
    "                if word in self.word_dict:\n",
    "                    self.word_dict[word] += 1\n",
    "                \n",
    "                else:\n",
    "                    self.word_dict[word] = 1\n",
    "\n",
    "        # create an empty list to store the vectors from the next step\n",
    "        list_all_vectors = []\n",
    "        \n",
    "        # create vector out of given dictionary of words\n",
    "        for document in self.documents:\n",
    "            \n",
    "            if self.lowercase == True:\n",
    "                document = document.lower()\n",
    "                        \n",
    "            if self.remove_punctuation == True:\n",
    "\n",
    "                # remove puntuation\n",
    "                punctuation_all = \"!#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "\n",
    "                # replace all punctuation with a empty space\n",
    "                for punctuation in punctuation_all:\n",
    "                    document = document.replace(punctuation, ' ')\n",
    "                \n",
    "            if self.remove_numbers == True:\n",
    "                \n",
    "                # remove numbers from the document\n",
    "                numbers = ['0123456789']\n",
    "                \n",
    "                for number in numbers:\n",
    "                    document = document.replace(number, ' ')\n",
    "            \n",
    "            vector_list = []\n",
    "            # creates a vector of 0 and 1's for every word in the dict. If the word was in the text, then 1, if not, then 0\n",
    "            for word in self.word_dict:\n",
    "\n",
    "                if word in document:\n",
    "                    vector_list.append(1)\n",
    "\n",
    "                else:\n",
    "                    vector_list.append(0) \n",
    "            \n",
    "            #Â append the vector representation of each text to the list of all vectors\n",
    "            list_all_vectors.append(vector_list)\n",
    "\n",
    "        # create numpy array out of the list of lists (vector)\n",
    "        self.array_all_vectors = np.array(list_all_vectors)\n",
    "        \n",
    "        return self.array_all_vectors # statement could be removed (can be used to print the vector representation)\n",
    "\n",
    "    \n",
    "    def create_vector_search_document(self, search_document):\n",
    "        \"\"\"\n",
    "        Helper function to create vector representation out of the search document.\n",
    "        \n",
    "        Args:\n",
    "            search_document: Document that should be compared with the documents in the corpus.\n",
    "\n",
    "        Returns:\n",
    "            Vector representation of the search document. \n",
    "        \"\"\"\n",
    "        vector_search_document = []\n",
    "        \n",
    "        # make the text lowercase to not differenciate between upper and lowercase words\n",
    "        if self.lowercase == True:\n",
    "            search_document = search_document.lower()\n",
    "                \n",
    "        # remove punctuation\n",
    "        if self.remove_punctuation == True:\n",
    "            \n",
    "            punctuation_all = \"!#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "            \n",
    "            # replace all punctuation with a empty space\n",
    "            for punctuation in punctuation_all:\n",
    "                document = search_document.replace(punctuation, ' ')\n",
    "                \n",
    "        if self.remove_numbers == True:\n",
    "                \n",
    "            # remove numbers from the document\n",
    "            numbers = ['0123456789']\n",
    "            \n",
    "            for number in numbers:\n",
    "                document = document.replace(number, ' ')\n",
    "        \n",
    "        for word in self.word_dict:\n",
    "            \n",
    "            # if a word from the corpus exists in the document add a 1 to the vector\n",
    "            if word in search_document:\n",
    "                vector_search_document.append(1)\n",
    "            \n",
    "            # if a word from the corpus does not exists in the document add a 0 to the vector\n",
    "            else:\n",
    "                vector_search_document.append(0)\n",
    "        \n",
    "        return vector_search_document\n",
    "        \n",
    "    \n",
    "    def similarity_euc_distance(self, search_document):\n",
    "        \"\"\"\n",
    "        Helper function to calculate the euclidean distance between the words in the corpus and the search document.\n",
    "        \n",
    "        Args:\n",
    "            search_document: Document that should be compared with the documents in the corpus.\n",
    "\n",
    "        Returns:\n",
    "            A list of the documents in the corpus, ordered by similarity to the search document.\n",
    "        \"\"\"\n",
    "        \n",
    "        vector_search_document = self.create_vector_search_document(search_document)\n",
    "\n",
    "        # Euclidean distance, low distance means documents are similar - using NumPy\n",
    "        #euc_dist_numpy = np.linalg.norm(self.array_all_vectors - vector_search_document, axis=1)\n",
    "\n",
    "        # Euclidean distance, low distance means documents are similar - using math.dist\n",
    "        euc_dist = np.array([])\n",
    "        for i in range(len(self.array_all_vectors)):\n",
    "            euc_dist = np.append(euc_dist, math.dist(self.array_all_vectors[i], vector_search_document))\n",
    "\n",
    "        # create a sorted list of tuples containing the number of words in common and the corresponding document\n",
    "        similarity_list = sorted(zip(euc_dist, self.documents), reverse=False) #ascending order \n",
    "\n",
    "        # extract the second element of the tuples from the list above \n",
    "        similar_documents = [x[1] for x in similarity_list]\n",
    "\n",
    "        return similar_documents\n",
    "\n",
    "        \n",
    "    def similarity_dot_product(self, search_document):\n",
    "        \"\"\"\n",
    "        Helper function to calculate the dot product between the words in the corpus and the search document.\n",
    "        \n",
    "        Args:\n",
    "            search_document: Document that should be compared with the documents in the corpus.\n",
    "\n",
    "        Returns:\n",
    "            A list of the documents in the corpus, ordered by similarity to the search document.\n",
    "        \"\"\"\n",
    "        \n",
    "        vector_search_document = self.create_vector_search_document(search_document)\n",
    "\n",
    "        # calculate the dot product between the two vectors, high value means documents are similar\n",
    "        dot_product = np.dot(self.array_all_vectors, vector_search_document)\n",
    "\n",
    "        # create a sorted list of tuples containing the number of words in common and the corresponding document\n",
    "        similarity_list = sorted(zip(dot_product, self.documents), reverse=True)\n",
    "\n",
    "        # extract the second element of the tuples from the list above \n",
    "        similar_documents = [x[1] for x in similarity_list]\n",
    "\n",
    "        return similar_documents\n",
    "        \n",
    "    \n",
    "    def show_similar_documents(self, similarity_type, search_document, top_n=False):\n",
    "        \"\"\"\n",
    "        Function to print a list similar documents to the search document, in descending order of similarity.\n",
    "        \n",
    "        Args:\n",
    "            similarity_type: Which distance/similarity measure to use in the similarity calculation\n",
    "                           \"euc\" will find the Euclidean distance\n",
    "                           \"dot\" will find the dot product\n",
    "            search_document: Document that should be compared with the documents in the corpus.\n",
    "            top_n: Number of similar documents to show, if False will show all documetns (Default: False)\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "            \n",
    "        Prints to screen:\n",
    "            A list of the documents in the corpus, ordered by similarity to the search document.\n",
    "        \"\"\"\n",
    "        \n",
    "        nl = '\\n -> '\n",
    "        \n",
    "        # check for invalid input\n",
    "        if type(search_document) == str:\n",
    "            \n",
    "            # to show all results results:\n",
    "            if top_n == False:\n",
    "\n",
    "                # check which similarity calculation is to be used\n",
    "                if similarity_type == \"euc\":\n",
    "                    print(f\"Similar documents using Euclidean distance (descending similarity, all documents shown):{nl}{nl.join(self.similarity_euc_distance(search_document))}\\n\")\n",
    "\n",
    "                elif similarity_type == \"dot\":\n",
    "                    print(f\"Similar documents using dot product (descending similarity, all documents shown):{nl}{nl.join(self.similarity_dot_product(search_document))}\\n\")\n",
    "\n",
    "                # give error if neither \"euc\" or \"dot\" given as input to similarity_type\n",
    "                else:\n",
    "                    print(\"Error: Invald input for similarity_type. Choose either \\\"dot\\\" for dot product or \\\"euc\\\" for Euclidean distance.\")\n",
    "\n",
    "            # show a specific number of results\n",
    "            elif type(top_n) == int:\n",
    "\n",
    "                # check that top_n is not bigger than number of documents\n",
    "                # if bigger then make top_n equal to number of documents\n",
    "                if top_n > len(self.documents):\n",
    "                    top_n = len(self.documents)\n",
    "\n",
    "\n",
    "                # check which similarity calculation is to be used\n",
    "                if similarity_type == \"euc\":\n",
    "                    print(f\"The {top_n} most similar documents using Euclidean distance (descending similarity):{nl}{nl.join(self.similarity_euc_distance(search_document)[:top_n])}\\n\")\n",
    "\n",
    "                elif similarity_type == \"dot\":\n",
    "                    print(f\"The {top_n} most similar documents using dot product (descending similarity):{nl}{nl.join(self.similarity_dot_product(search_document)[:top_n])}\\n\")\n",
    "\n",
    "                # give error if neither \"euc\" or \"dot\" given as input to similarity_type\n",
    "                else:\n",
    "                    print(\"Error: Invald input for similarity_type. Choose either \\\"dot\\\" for dot product or \\\"euc\\\" for Euclidean distance.\")\n",
    "\n",
    "            else:\n",
    "                print(\"Error: Invalid input for top_n given. Please enter an integer value and try again.\")\n",
    "        \n",
    "        else:\n",
    "            print('Error: The input given for search document is invalid. Please give a document or string and try again.')\n",
    "            \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_most_used_words(self, top_n=10): # returns it (help the next function)\n",
    "        \"\"\"\n",
    "        Helper function to get the most used words the corpus.\n",
    "        \n",
    "        Args:\n",
    "            top_n: Number of results (Default: 10)\n",
    "\n",
    "        Returns:\n",
    "            A list of the most used words in the corpus, sorted by frequency in descending order.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(top_n) == int:\n",
    "            # sort words based on the frequency they appear in the corpus in descending order\n",
    "            # the second element is the number of times the word appears therefore X[1]\n",
    "            sorted_words = sorted(self.word_dict.items(), key=lambda x: x[1], reverse=True) #????\n",
    "\n",
    "            #Â get the top_n words from the sorted words\n",
    "            top_words = [word[0] for word in sorted_words][:top_n]\n",
    "\n",
    "            return top_words\n",
    "        \n",
    "        else:\n",
    "            print('Error: Invalid input given for top_n. Please enter an integer value and try again.')\n",
    "            return \n",
    "\n",
    "    def show_most_used_words(self, top_n=10): # showing the nice list - prints to the output\n",
    "        \"\"\"\n",
    "        Function to show the most used words the corpus to the user.\n",
    "        \n",
    "        Args:\n",
    "            top_n: Number of results (Default: 10)\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "            \n",
    "        Prints to screen:\n",
    "            A list of the most used words in the corpus, sorted by frequency in descending order.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(top_n) == int:\n",
    "            print(f\"The {top_n} most common words used in the corpus:\")\n",
    "            print(f\"{self.get_most_used_words(top_n)}\\n\")\n",
    "\n",
    "        else:\n",
    "            print('Error: Invalid input given for top_n. Please enter an integer value and try again.')\n",
    "            \n",
    "        return         \n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Function to overide the string representation for an object of the Corpus class, when the user uses print()\n",
    "        \"\"\"\n",
    "        return f\"Name of the Corpus:\\n{self.name}\\n\\nNumber of documents in the Corpus:\\n{len(self.documents)}\\n\\nPlease use the .show_docs() method to see a list of all documents in this Corpus.\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27b930",
   "metadata": {},
   "source": [
    "## Testing the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10eba625",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the Corpus:\n",
      "Newspaper\n",
      "\n",
      "Number of documents in the Corpus:\n",
      "5\n",
      "\n",
      "Please use the .show_docs() method to see a list of all documents in this Corpus.\n",
      "\n",
      "All documents in the Newspaper Corpus: \n",
      " -> Hello this is an Example sentence.\n",
      " -> The sun is shining today.\n",
      " -> Hello! The sun is shining for example.\n",
      " -> This really long sentence has many words and is longer than the above sentences\n",
      " -> This text has almost nothing to do with the other ones.\n",
      "\n",
      "The search document is:\n",
      "Hello this is a good example for a sun.\n",
      "\n",
      "The 5 most common words used in the corpus:\n",
      "['is', 'the', 'this', 'hello', 'example']\n",
      "\n",
      "Similar documents using dot product (descending similarity, all documents shown):\n",
      " -> Hello! The sun is shining for example.\n",
      " -> Hello this is an Example sentence.\n",
      " -> This text has almost nothing to do with the other ones.\n",
      " -> This really long sentence has many words and is longer than the above sentences\n",
      " -> The sun is shining today.\n",
      "\n",
      "The 3 most similar documents using Euclidean distance (descending similarity):\n",
      " -> Hello! The sun is shining for example.\n",
      " -> Hello this is an Example sentence.\n",
      " -> The sun is shining today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Creating a Corpus ####\n",
    "\n",
    "# create some test documents\n",
    "document1 = \"Hello this is an Example sentence.\"\n",
    "document2 = \"The sun is shining today.\"\n",
    "document3 = \"Hello! The sun is shining for example.\"\n",
    "document4 = \"This text has almost nothing to do with the other ones.\"\n",
    "document5 = \"This really long sentence has many words and is longer than the above sentences\" \n",
    "\n",
    "# create search document\n",
    "search_document = \"Hello this is a good example for a sun.\"\n",
    "\n",
    "# initiate a corpus\n",
    "Corpus1 = Corpus('Newspaper')\n",
    "\n",
    "# add either a list of documents or a single document to the corpus\n",
    "Corpus1.add_doc([document1, document2, document3, document5])\n",
    "Corpus1.add_doc(document4)\n",
    "\n",
    "# get information on the Corpus created\n",
    "print(Corpus1)\n",
    "Corpus1.show_docs()\n",
    "print(f\"The search document is:\\n{search_document}\\n\")\n",
    "\n",
    "\n",
    "#### Running the similarity program on the new Corpus ####\n",
    "\n",
    "# Find the most used words in a corpus\n",
    "Corpus1.show_most_used_words(5)\n",
    "\n",
    "# compare the search document with the documents contained in the corpus - dot product\n",
    "Corpus1.show_similar_documents(\"dot\", search_document)\n",
    "\n",
    "# compare the search document with the documents contained in the corpus - euclidean, only top 3 results\n",
    "Corpus1.show_similar_documents(\"euc\", search_document, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26608f",
   "metadata": {},
   "source": [
    "## Testing the error-handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33efdcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Input document(s) must be a string or a list of strings. No new documents added to the Newspaper corpus, please try again.\n",
      "\n",
      "Error: Input document does not exist in the Newspaper corpus, please try again.\n",
      "Error: Only one document can be removed at a time, please try again.\n",
      "Error: Invalid input entered. The input must be a single document, please try again.\n",
      "\n",
      "Error: The input given for search document is invalid. Please give a document or string and try again.\n",
      "Error: Invalid input for top_n given. Please enter an integer value and try again.\n",
      "Error: Invald input for similarity_type. Choose either \"dot\" for dot product or \"euc\" for Euclidean distance.\n",
      "\n",
      "Error: Invalid input given for top_n. Please enter an integer value and try again.\n"
     ]
    }
   ],
   "source": [
    "# testing error-handling \n",
    "Corpus1.add_doc(3)\n",
    "print()\n",
    "\n",
    "Corpus1.remove_doc(\"hi\")\n",
    "Corpus1.remove_doc([\"hi\", \"hello\"])\n",
    "Corpus1.remove_doc(34)\n",
    "print()\n",
    "\n",
    "Corpus1.show_similar_documents(\"dot\", 24, top_n=False)\n",
    "Corpus1.show_similar_documents(\"dot\", search_document, top_n=\"five\")\n",
    "Corpus1.show_similar_documents(\"manhattan\", search_document, top_n=False)\n",
    "print()\n",
    "\n",
    "Corpus1.show_most_used_words(\"five\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947662a8",
   "metadata": {},
   "source": [
    "## Testing with longer text document examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd34e751",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the Corpus:\n",
      "Stories\n",
      "\n",
      "Number of documents in the Corpus:\n",
      "5\n",
      "\n",
      "Please use the .show_docs() method to see a list of all documents in this Corpus.\n",
      "\n",
      "The 2 most similar documents using Euclidean distance (descending similarity):\n",
      " -> April seriously wondered about her sleeping partner choices. She looked at her bed and what a mess it had become. How did she get to the point in her life where she had two dogs, three cats, and a raccoon sleeping with her every night?\n",
      " -> He stepped away from the mic. This was the best take he had done so far, but something seemed missing. Then it struck him all at once. Visuals ran in front of his eyes and music rang in his ears. His eager fingers went to work in an attempt to capture his thoughts hoping the results would produce something that was at least half their glory.\n",
      "\n",
      "\n",
      "The 7 most common words used in the corpus:\n",
      "['the', 'a', 'i', 'to', 'and', 'my', 'out']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import some test documents\n",
    "docs = []\n",
    "for i in range(1,7):\n",
    "    with open(f'DS_FinalProject_Question3_Documents/Doc{i}') as f:\n",
    "        doc = f.read()\n",
    "        docs.append(doc)\n",
    "\n",
    "# import search document\n",
    "with open('DS_FinalProject_Question3_Documents/Doc1') as f:\n",
    "    search_doc = f.read()\n",
    "    \n",
    "# initialise new corpus\n",
    "Corpus2 = Corpus('Stories')\n",
    "\n",
    "# add documents to corpus\n",
    "Corpus2.add_doc(docs)\n",
    "\n",
    "# search document was also included when intially loaded, so remove from corpus\n",
    "Corpus2.remove_doc(search_doc)\n",
    "\n",
    "# see the Corpus\n",
    "print(Corpus2)\n",
    "\n",
    "# create vector representation of corpus\n",
    "Corpus2.create_vector_representation()\n",
    "\n",
    "# show top 2 similar documents, using dot product calculation\n",
    "Corpus2.show_similar_documents(\"euc\", search_document, top_n=2)\n",
    "\n",
    "# show 7 most used words\n",
    "Corpus2.show_most_used_words(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d3c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87010770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
